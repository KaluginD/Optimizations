{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.special import expit\n",
    "from scipy.optimize.linesearch import scalar_search_wolfe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nose.tools import assert_almost_equal, ok_, eq_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "b = np.array([1, 1, -1, 1])\n",
    "regcoef = 0.5\n",
    "m = len(b)\n",
    "\n",
    "x = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSmoothOracle(object):\n",
    "    \"\"\"\n",
    "    Base class for implementation of oracles.\n",
    "    \"\"\"\n",
    "    def func(self, x):\n",
    "        \"\"\"\n",
    "        Computes the value of function at point x.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('Func oracle is not implemented.')\n",
    "\n",
    "    def grad(self, x):\n",
    "        \"\"\"\n",
    "        Computes the gradient at point x.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('Grad oracle is not implemented.')\n",
    "    \n",
    "    def hess(self, x):\n",
    "        \"\"\"\n",
    "        Computes the Hessian matrix at point x.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('Hessian oracle is not implemented.')\n",
    "    \n",
    "    def func_directional(self, x, d, alpha):\n",
    "        \"\"\"\n",
    "        Computes phi(alpha) = f(x + alpha*d).\n",
    "        \"\"\"\n",
    "        return np.squeeze(self.func(x + alpha * d))\n",
    "\n",
    "    def grad_directional(self, x, d, alpha):\n",
    "        \"\"\"\n",
    "        Computes phi'(alpha) = (f(x + alpha*d))'_{alpha}\n",
    "        \"\"\"\n",
    "        return np.squeeze(self.grad(x + alpha * d).dot(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegL2Oracle(BaseSmoothOracle):\n",
    "    \"\"\"\n",
    "    Oracle for logistic regression with l2 regularization:\n",
    "         func(x) = 1/m sum_i log(1 + exp(-b_i * a_i^T x)) + regcoef / 2 ||x||_2^2.\n",
    "\n",
    "    Let A and b be parameters of the logistic regression (feature matrix\n",
    "    and labels vector respectively).\n",
    "    For user-friendly interface use create_log_reg_oracle()\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        matvec_Ax : function\n",
    "            Computes matrix-vector product Ax, where x is a vector of size n.\n",
    "        matvec_ATx : function of x\n",
    "            Computes matrix-vector product A^Tx, where x is a vector of size m.\n",
    "        matmat_ATsA : function\n",
    "            Computes matrix-matrix-matrix product A^T * Diag(s) * A,\n",
    "    \"\"\"\n",
    "    def __init__(self, matvec_Ax, matvec_ATx, matmat_ATsA, b, regcoef):\n",
    "        self.matvec_Ax = matvec_Ax\n",
    "        self.matvec_ATx = matvec_ATx\n",
    "        self.matmat_ATsA = matmat_ATsA\n",
    "        self.b = b\n",
    "        self.m = len(b)\n",
    "        self.regcoef = regcoef\n",
    "\n",
    "    def func(self, x):\n",
    "        func = np.logaddexp(0, -self.b * self.matvec_Ax(x)).mean() + self.regcoef * (x @ x) / 2\n",
    "        return func\n",
    "\n",
    "    def grad(self, x):\n",
    "        expit_curr = expit(-self.b * self.matvec_Ax(x))\n",
    "        grad = -self.matvec_ATx(self.b * expit_curr) / self.m + self.regcoef * x\n",
    "        return grad\n",
    "\n",
    "    def hess(self, x):\n",
    "        expit_curr = expit(-self.b @ self.matvec_Ax(x))\n",
    "        n = len(x)\n",
    "        ones = np.array([1] * self.m)\n",
    "        hess = expit_curr * (1 - expit_curr) * self.matmat_ATsA(ones) / self.m + self.regcoef * np.eye(n)\n",
    "        return hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_reg_oracle(A, b, regcoef, oracle_type='usual'):\n",
    "    \"\"\"\n",
    "    Auxiliary function for creating logistic regression oracles.\n",
    "        `oracle_type` must be either 'usual' or 'optimized'\n",
    "    \"\"\"\n",
    "    matvec_Ax = lambda x: A @ x  # TODO: Implement\n",
    "    matvec_ATx = lambda x: A.T @ x  # TODO: Implement\n",
    "\n",
    "    def matmat_ATsA(s):\n",
    "        # TODO: Implement\n",
    "        return A.T @ np.diag(s) @ A\n",
    "\n",
    "    if oracle_type == 'usual':\n",
    "        oracle = LogRegL2Oracle\n",
    "    elif oracle_type == 'optimized':\n",
    "        oracle = LogRegL2OptimizedOracle\n",
    "    else:\n",
    "        raise 'Unknown oracle_type=%s' % oracle_type\n",
    "    return oracle(matvec_Ax, matvec_ATx, matmat_ATsA, b, regcoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "b = np.array([1, 1, -1, 1])\n",
    "reg_coef = 0.5\n",
    "\n",
    "# Logistic regression oracle:\n",
    "logreg = create_log_reg_oracle(A, b, reg_coef, oracle_type='usual')\n",
    "\n",
    "# Check at point x = [0, 0]\n",
    "x = np.zeros(2)\n",
    "assert_almost_equal(logreg.func(x), 0.693147180)\n",
    "ok_(np.allclose(logreg.grad(x), [0, -0.25]))\n",
    "ok_(np.allclose(logreg.hess(x), [[0.625, 0.0625], [0.0625, 0.625]]))\n",
    "ok_(isinstance(logreg.grad(x), np.ndarray))\n",
    "ok_(isinstance(logreg.hess(x), np.ndarray))\n",
    "\n",
    "# Check func_direction and grad_direction oracles at\n",
    "# x = [0, 0], d = [1, 1], alpha = 0.5 and 1.0\n",
    "x = np.zeros(2)\n",
    "d = np.ones(2)\n",
    "assert_almost_equal(logreg.func_directional(x, d, alpha=0.5),\n",
    "                    0.7386407091095)\n",
    "assert_almost_equal(logreg.grad_directional(x, d, alpha=0.5),\n",
    "                    0.4267589549159)\n",
    "assert_almost_equal(logreg.func_directional(x, d, alpha=1.0),\n",
    "                    1.1116496416598)\n",
    "assert_almost_equal(logreg.grad_directional(x, d, alpha=1.0),\n",
    "                    1.0559278283039)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7386407091095953"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.func_directional(x, d, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "x = x + alpha * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for @: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-576b210853b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-564ba5d86b5b>\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogaddexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatvec_Ax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregcoef\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for @: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "logreg.func([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    func = np.logaddexp(0, -b * matvec_Ax(x)).mean() + regcoef * np.linalg.norm(x) / 2\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matvec_Ax = lambda x: A @ x  # TODO: Implement\n",
    "matvec_ATx = lambda x: A.T @ x  # TODO: Implement\n",
    "\n",
    "def matmat_ATsA(s):\n",
    "    # TODO: Implement\n",
    "    return A.T @ np.diag(s) @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7904174044062322"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5618640138128631"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7386407091095 - regcoef * np.linalg.norm(x) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0. , -0.5,  0.5, -1. ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-b * matvec_Ax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticOracle(BaseSmoothOracle):\n",
    "    \"\"\"\n",
    "    Oracle for quadratic function:\n",
    "       func(x) = 1/2 x^TAx - b^Tx.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A, b):\n",
    "        if not scipy.sparse.isspmatrix_dia(A) and not np.allclose(A, A.T):\n",
    "            raise ValueError('A should be a symmetric matrix.')\n",
    "        self.A = A\n",
    "        self.b = b\n",
    "\n",
    "    def func(self, x):\n",
    "        return 0.5 * np.dot(self.A.dot(x), x) - self.b.dot(x)\n",
    "\n",
    "    def grad(self, x):\n",
    "        return self.A.dot(x) - self.b\n",
    "\n",
    "    def hess(self, x):\n",
    "        return self.A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_finite_diff(func, x, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Returns approximation of the gradient using finite differences:\n",
    "        result_i := (f(x + eps * e_i) - f(x)) / eps,\n",
    "        where e_i are coordinate vectors:\n",
    "        e_i = (0, 0, ..., 0, 1, 0, ..., 0)\n",
    "                          >> i <<\n",
    "    \"\"\"\n",
    "    # TODO: Implement numerical estimation of the gradient\n",
    "    n = len(x)\n",
    "    grad_finite_diff = np.array([0.] * n)\n",
    "    print(func(x))\n",
    "    for i in range(n):\n",
    "        e_i = np.zeros(n)\n",
    "        e_i[i] = 1\n",
    "        print('i', (func(x + eps * e_i) - func(x)) / eps)\n",
    "        grad_finite_diff[i] = (func(x + eps * e_i) - func(x)) / eps\n",
    "    return grad_finite_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "i -0.999999995\n",
      "i -1.9999999949999998\n",
      "i -2.9999999950000005\n",
      "[-1.         -1.99999999 -3.        ]\n"
     ]
    }
   ],
   "source": [
    "A = np.eye(3)\n",
    "b = np.array([1, 2, 3])\n",
    "quadratic = QuadraticOracle(A, b)\n",
    "g = grad_finite_diff(quadratic.func, np.zeros(3))\n",
    "print(g)\n",
    "ok_(isinstance(g, np.ndarray))\n",
    "ok_(np.allclose(g, -b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quadratic():\n",
    "    # Quadratic function:\n",
    "    #   f(x) = 1/2 x^T x - [1, 2, 3]^T x\n",
    "    A = np.eye(3)\n",
    "    b = np.array([1, 2, 3])\n",
    "    return QuadraticOracle(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineSearchTool(object):\n",
    "    \"\"\"\n",
    "    Line search tool for adaptively tuning the step size of the algorithm.\n",
    "\n",
    "    method : String containing 'Wolfe', 'Armijo' or 'Constant'\n",
    "        Method of tuning step-size.\n",
    "        Must be be one of the following strings:\n",
    "            - 'Wolfe' -- enforce strong Wolfe conditions;\n",
    "            - 'Armijo\" -- adaptive Armijo rule;\n",
    "            - 'Constant' -- constant step size.\n",
    "    kwargs :\n",
    "        Additional parameters of line_search method:\n",
    "\n",
    "        If method == 'Wolfe':\n",
    "            c1, c2 : Constants for strong Wolfe conditions\n",
    "            alpha_0 : Starting point for the backtracking procedure\n",
    "                to be used in Armijo method in case of failure of Wolfe method.\n",
    "        If method == 'Armijo':\n",
    "            c1 : Constant for Armijo rule\n",
    "            alpha_0 : Starting point for the backtracking procedure.\n",
    "        If method == 'Constant':\n",
    "            c : The step size which is returned on every step.\n",
    "    \"\"\"\n",
    "    def __init__(self, method='Wolfe', **kwargs):\n",
    "        self._method = method\n",
    "        if self._method == 'Wolfe':\n",
    "            self.c1 = kwargs.get('c1', 1e-4)\n",
    "            self.c2 = kwargs.get('c2', 0.9)\n",
    "            self.alpha_0 = kwargs.get('alpha_0', 1.0)\n",
    "        elif self._method == 'Armijo':\n",
    "            self.c1 = kwargs.get('c1', 1e-4)\n",
    "            self.alpha_0 = kwargs.get('alpha_0', 1.0)\n",
    "        elif self._method == 'Constant':\n",
    "            self.c = kwargs.get('c', 1.0)\n",
    "        else:\n",
    "            raise ValueError('Unknown method {}'.format(method))\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, options):\n",
    "        if type(options) != dict:\n",
    "            raise TypeError('LineSearchTool initializer must be of type dict')\n",
    "        return cls(**options)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return self.__dict__\n",
    "\n",
    "    def line_search(self, oracle, x_k, d_k, previous_alpha=None):\n",
    "        \"\"\"\n",
    "        Finds the step size alpha for a given starting point x_k\n",
    "        and for a given search direction d_k that satisfies necessary\n",
    "        conditions for phi(alpha) = oracle.func(x_k + alpha * d_k).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        oracle : BaseSmoothOracle-descendant object\n",
    "            Oracle with .func_directional() and .grad_directional() methods implemented for computing\n",
    "            function values and its directional derivatives.\n",
    "        x_k : np.array\n",
    "            Starting point\n",
    "        d_k : np.array\n",
    "            Search direction\n",
    "        previous_alpha : float or None\n",
    "            Starting point to use instead of self.alpha_0 to keep the progress from\n",
    "             previous steps. If None, self.alpha_0, is used as a starting point.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        alpha : float or None if failure\n",
    "            Chosen step size\n",
    "        \"\"\"\n",
    "        # TODO: Implement line search procedures for Armijo, Wolfe and Constant steps.\n",
    "        if self._method == 'Constant':\n",
    "            return self.c\n",
    "        alpha_0 = previous_alpha if previous_alpha else self.alpha_0\n",
    "        phi = lambda a: oracle.func_directional(x_k, d_k, a)\n",
    "        derphi = lambda a: oracle.grad_directional(x_k, d_k, a)\n",
    "        c2 = self.c2 if self._method == 'Wolfe' else 0\n",
    "        print(alpha_0)\n",
    "        alpha, _, _, _ = scalar_search_wolfe2(phi=phi,\n",
    "                                              derphi=derphi,\n",
    "                                              phi0=phi(0),\n",
    "                                              derphi0=derphi(0),\n",
    "                                              c1=self.c1,\n",
    "                                              c2=c2,  amax=alpha_0)\n",
    "        print(alpha)\n",
    "        if alpha is None:\n",
    "            alpha = alpha_0\n",
    "            while phi(alpha) > phi(0) + self.c1 * alpha * derphi(0):\n",
    "                alpha /= 2\n",
    "        print(alpha)\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = get_quadratic()\n",
    "x = np.array([100, 0, 0])\n",
    "d = np.array([-1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant line search\n",
    "ls_tool = LineSearchTool(method='Constant', c=1.0)\n",
    "assert_almost_equal(ls_tool.line_search(oracle, x, d, ), 1.0)\n",
    "ls_tool = LineSearchTool(method='Constant', c=10.0)\n",
    "assert_almost_equal(ls_tool.line_search(oracle, x, d), 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "None\n",
      "12.5\n"
     ]
    }
   ],
   "source": [
    "# Armijo rule\n",
    "ls_tool = LineSearchTool(method='Armijo', alpha_0=100.0, c1=0.9)\n",
    "assert_almost_equal(ls_tool.line_search(oracle, x, d), 12.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "None\n",
      "1.0\n",
      "100\n",
      "None\n",
      "6.25\n",
      "10\n",
      "None\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:421: LineSearchWarning: The line search algorithm could not find a solution less than or equal to amax: 1.0\n",
      "  warn(msg, LineSearchWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:421: LineSearchWarning: The line search algorithm could not find a solution less than or equal to amax: 10\n",
      "  warn(msg, LineSearchWarning)\n"
     ]
    }
   ],
   "source": [
    "ls_tool = LineSearchTool(method='Armijo', alpha_0=100, c1=0.9)\n",
    "assert_almost_equal(ls_tool.line_search(oracle, x, d, previous_alpha=1.0), 1.0)\n",
    "\n",
    "ls_tool = LineSearchTool(method='Armijo', alpha_0=100, c1=0.95)\n",
    "assert_almost_equal(ls_tool.line_search(oracle, x, d), 6.25)\n",
    "ls_tool = LineSearchTool(method='Armijo', alpha_0=10, c1=0.9)\n",
    "assert_almost_equal(ls_tool.line_search(oracle, x, d), 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10., 10., 10.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(3) * 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_search_tool(line_search_options=None):\n",
    "    if line_search_options:\n",
    "        if type(line_search_options) is LineSearchTool:\n",
    "            return line_search_options\n",
    "        else:\n",
    "            return LineSearchTool.from_dict(line_search_options)\n",
    "    else:\n",
    "        return LineSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = get_quadratic()\n",
    "x0 = np.ones(3) * 10.0\n",
    "d0 = np.array([9., 8., 7.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_search_tool = get_line_search_tool(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "None\n",
      "5.551115123125783e-17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.551115123125783e-17"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_search_tool.line_search(oracle, x0, d0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.grad_directional(x0, d0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.0194"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.func(x0) + 1e-4 * 194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.func([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    'a' : 1,\n",
    "    'b' : 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as sla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [-1, 1],\n",
    "    [1, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sla.cho_solve(sla.cho_factor(A), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "1-th leading minor of the array is not positive definite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-672487a98f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcho_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcho_factor\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \"\"\"\n\u001b[1;32m    141\u001b[0m     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=False,\n\u001b[0;32m--> 142\u001b[0;31m                          check_finite=check_finite)\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n\u001b[0;32m---> 40\u001b[0;31m                           \"definite\" % info)\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         raise ValueError('LAPACK reported an illegal value in {}-th argument'\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 1-th leading minor of the array is not positive definite"
     ]
    }
   ],
   "source": [
    "sla.cho_factor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [1, 1],\n",
    "    [1, 2]\n",
    "])\n",
    "b = np.array([1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1.],\n",
       "        [1., 1.]]), False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.cho_factor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  2.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.cho_solve(sla.cho_factor(A), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([10.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00990099]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1 / (np.power(x, 2) + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "1-th leading minor of the array is not positive definite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-672487a98f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcho_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcho_factor\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \"\"\"\n\u001b[1;32m    141\u001b[0m     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=False,\n\u001b[0;32m--> 142\u001b[0;31m                          check_finite=check_finite)\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n\u001b[0;32m---> 40\u001b[0;31m                           \"definite\" % info)\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         raise ValueError('LAPACK reported an illegal value in {}-th argument'\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 1-th leading minor of the array is not positive definite"
     ]
    }
   ],
   "source": [
    "sla.cho_factor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03574654, 0.43006079])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
